{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XAlL187LQ0jBwxzEdroIzAuGqY-806GP",
      "authorship_tag": "ABX9TyPpvjyloulq9ObaLmSfN1U8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haaaram/MS-AIschool/blob/main/CV/image_augmentation_Fail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa--4prWdbH3"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image, ImageFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomData(Dataset):\n",
        "  def __init__(self, data_dir, transform=None):\n",
        "    self.data_dir = glob.glob(os.path.join(data_dir, \"*\", \"*.jpg\"))\n",
        "    self.transforms = transforms\n",
        "    self.label_dir = {'traffic light':0, 'limit sign':1, 'stop sign':2,\n",
        "                      'animal':3, 'car':4, 'human':5, 'right_sign':6, 'left_sign':7}\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    image_path = self.data_dir[item]\n",
        "    label_name = image_path.split('\\\\')[1]\n",
        "    label = self.label_dict[label_name]\n",
        "\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    if self.transforms is not None :\n",
        "      image= self.transforms(image)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_dir)"
      ],
      "metadata": {
        "id": "HV5XfrlrjvYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torchvision.models.mobilenetv2 import mobilenet_v2\n",
        "from torchvision.models.efficientnet import efficientnet_v2_s\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "M2e5IltcDKEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, epochs, optimizer, criterion, device) :\n",
        "    best_val_acc = 0.0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    print(\"Train ....\")\n",
        "    for epoch in range(epochs) :\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        train_acc = 0.0\n",
        "\n",
        "        model.train()\n",
        "        # tqdm\n",
        "        train_loader_iter = tqdm(train_loader, desc=(f\"Epoch : {epoch + 1}/{epochs}\"), leave=False)\n",
        "\n",
        "        for i, (data, target) in enumerate(train_loader_iter) :\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            # acc\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            train_acc += (pred == target).sum().item()\n",
        "\n",
        "            train_loader_iter.set_postfix({\"Loss\" :  loss.item()})\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "        # eval\n",
        "        model.eval()\n",
        "        with torch.no_grad() :\n",
        "            for data, target in val_loader :\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "\n",
        "                output = model(data)\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                val_acc += pred.eq(target.view_as(pred)).sum().item()\n",
        "                val_loss += criterion(output, target).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = val_acc / len(val_loader.dataset)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # save model\n",
        "        if val_acc > best_val_acc :\n",
        "            torch.save(model.state_dict(), \"./eff.pt\")\n",
        "            best_val_acc = val_acc\n",
        "        print(f\"Epoch [{epoch + 1} / {epochs}] , Train loss [{train_loss:.4f}],\"\n",
        "              f\"Val loss [{val_loss :.4f}], Train ACC [{train_acc:.4f}],\"\n",
        "              f\"Val ACC [{val_acc:.4f}]\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"./last_eff.pt\")\n",
        "    return  model, train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "def main() :\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = efficientnet_v2_s(pretrained=True)\n",
        "    in_features_ = 1280\n",
        "    model.classifier[1] = nn.Linear(in_features_, 6)\n",
        "    model.to(device)\n",
        "\n",
        "    # aug\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.4),\n",
        "        transforms.RandomVerticalFlip(p=0.4),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.RandAugment(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5),(0.2,0.2,0.2))\n",
        "    ])\n",
        "\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.2, 0.2, 0.2))\n",
        "    ])\n",
        "\n",
        "    # dataset dataloader\n",
        "    train_dataset = CustomData(\"./org_dataset/Train/\", transforms=train_transforms)\n",
        "    val_dataset = CustomData(\"./org_dataset/Valid/\", transforms=val_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=46, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=46, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # loss function optimizer, epochs\n",
        "    epochs = 50\n",
        "    criterion = CrossEntropyLoss().to(device)\n",
        "    optimizer = Lion(model.parameters(),lr=0.001 , weight_decay=1e-2)\n",
        "\n",
        "    train(model,train_loader,val_loader,epochs,optimizer,criterion,device)\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "SAkqgUuBDb8E",
        "outputId": "ae09e75d-e618-412f-de60-6687af4ea6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-93c4616e87ee>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-93c4616e87ee>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m### import trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{PATH}/best_mobilenet_v2.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# print(list(model.parameters()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/dataset/best_mobilenet_v2.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DYa4O72RERim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}